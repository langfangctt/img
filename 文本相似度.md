# 运用文本相似度实现（证券）智能客服

[TOC]

## 第一章 项目背景

### 1.1 提出原因

&emsp;&emsp;众所周知，客服是直接服务于客户的，在企业与客户的合作过程中起到了纽带的作用。客服的处理业务能力在很大程度上都代表着公司的形象，客服的工作能力和企业的利益息息相关。随着公司客户的日益增多，公司提供的业务逐渐完善、丰富，客服的工作也开始变得繁琐、复杂，甚至会导致客服人员的工作效率与质量降低，并间接影响了人员的招聘与管理，最终导致客户体验下降，影响公司盈利。

&emsp;&emsp;为了解决这些问题，AI客服随之问世，极大地缓解了企业的这些难题痛点。而实现AI客服的关键技术之一就是文本相似度计算技术。良好的相似度计算算法可以很好的提高，甚至很大程度上决定了计算结果的精准，直接影响着AI客服查询推荐、自动问答的性能。

&emsp;&emsp;因此，如何设计出更好的相似度计算方法吸引了许多工业界和学术界相关研究人员参与其中。除此之外，面对不同的服务领域，相似度计算结果的精度也会有所不同。针对该问题，本项目将以金融服务领域为主要服务对象，结合现有文本相似度计算算法创新的研究设计出适用性更好、精准度更高的相似度计算方法，从根本上进一步提高AI客服的服务效果。

### 1.2 环境背景

&emsp;&emsp;大数据时代背景下，越来越多的信息知识暴漏在人们面前，人们迫切的希望从海量信息中获取与自身需求或兴趣吻合度高的内容，越来越依赖于像搜索引擎、自动问答系统这样的应用来获取信息。因此，如何提升这类应用的精准度就成为了许多相关研究人员的首要考虑的问题，即如何提高文本相似度算法的精准度问题。

&emsp;&emsp;文本相似度是在语言学、心理学和信息理论等领域内均被广泛研究的重要课题，尤其在自然语言处理方面，文本相似度的判断和计算是其中具有重要意义和研究价值的一部分内容。

&emsp;&emsp;伴随着自然语言处理的发展，文本相似度的研究一开始是基于规则的方法慢慢向前发展，直到上世纪末，基于统计机器学习的方法的出现打破了这一现状，并成为了新的主流技术一直发展至今。到今天，仍然有许多基于统计机器学习的相关模型被提出。然而，基于统计机器学习的方法往往需要大量的人力来进行特征的提取和筛选，而且针对不同的领域任务，相似度计算的算法和模型也各不相同，更重要的是基于统计机器学习的方法逐渐到达一个性能的天花板，很难有更高的提升空间。

&emsp;&emsp;近几年来，深度学习在各个领域上展现出前所未有的表达能力，吸引了大量的研究人员对其进行研究。研究表明，深度学习在自然语言处理的各国任务中也取得了非常显著的效果，特别说实在文本分类、情感分析等任务上，基于深度学习的算法可以更大限度的利用上下文的信息，提高输入表征的信息量，使得计算结果更加准确。

### 1.3 项目意义

- **项目研究的意义首先在于可操作性。**如今，深度学习架构、算法在计算机视觉、模式识别领域已经取得惊人的进展。在这种趋势之下，近期基于深度学习新方法的 NLP 研究有了极大增长。而且，近年来的各种研究表明，深度学习在自然语言处理领域有很好的表现。
- **创新性是技术发展的前提。**这里将利用目前流行的word2vec词嵌入向量表示方法对输入的语句进行表征，结合LSTM和CNN提取句子中的前后以来信息和句子内的局部信息计算出新的句子向量表征，然后结合句子间的额外特征进行句子间的相似度计算。基于神经网络的句子相似度计算方法克服了句子语义表示上的词鸿沟问题，可以让计算机识别不同表示但是意思相同的句子，同时可以从不同角度来提取句子中的信息，更加丰富的对句子进行表示，使计算结果更加精确。
- **进一步提升算法精准度**，具有理论与实践的双重重要意义。虽然如今国内外研究人员已经研究出了许多计算效果还不错的研究成果，但在文本相似度计算方面仍然存在着些许不足，如基于传统特征提取的文本相似度计算方法需要花费大量的人力资源来对文本间的特征进行人工提取和筛选、基于深度学习的文本相似度计算模型的结构相对单一等等。除此之外，文本相似度算法精准度的提高将直接影响到AI客服、搜索引擎等应用的服务性能。因此，结合现有文本相似度研究结果继续研究设计文本相似度算法，进一步提升算法精准度是非常有必要性的，同时也具有很高的理论研究意义和实际应用价值。

## 第二章 调研分析

### 2.1 中文分词

> &emsp;&emsp;*NER一直是NLP领域中的研究热点，从早期基于词典和规则的方法，到传统机器学习的方法，到近年来基于深度学习的方法，NER研究进展的大概趋势大致如下图所示。*
>
> <img src="https://github.com/natsuRen/img/blob/master/img/01.jpg?raw=true" style="zoom:20">
>
> &emsp;&emsp;*中文分词是中文文本处理的一个基础步骤，也是中文人机自然语言交互的基础模块。不同于英文的是，中文句子中没有词的界限，因此在进行中文自然语言处理时，通常需要先进行分词，分词效果将直接影响词性、句法树等模块的效果。*

&emsp;&emsp;中文分词根据实现原理和特点，主要分为以下2个类别：

#### 2.1.1 基于词典的分词方法

> &emsp;&emsp;*也称字符串匹配分词算法。该算法是按照一定的策略将待匹配的字符串和一个已建立好的“充分大的”词典中的词进行匹配，若找到某个词条，则说明匹配成功，识别了该词。*
>

- **正向最大匹配法（FMM）**

  &emsp;&emsp;将一段字符串按定长进行分隔，然后将分隔的子字符串从左到右与字典中的词进行匹配，如果匹配成功则进行下一轮匹配，否则将子字符串从末尾去除一个字，再进行匹配，如此反复，直到所有字符串处理完毕。

- **逆向最大匹配法（RMM）**

  &emsp;&emsp;将一段字符串按定长进行分隔，然后将分隔的子字符串从右到左与字典中的词进行匹配，如果匹配成功则进行下一轮匹配，否则将子字符串从末尾去除一个字，再进行匹配，如此反复，直到所有字符串处理完毕。

- **双向最大匹配法（BM）**

  &emsp;&emsp;将正向最大匹配法得到的分词结果和逆向最大匹配法的到的结果进行比较，如果正反向分词结果词数不同，则取分词数量较少的那个。如果分词结果词数相同且分词结果相同，可返回任意一个。如果分词结果词数相同但分词结果不同，则返回其中单字较少的那个。

> &emsp;&emsp;*基于词典的分词算法是应用最广泛、分词速度最快的。很长一段时间内研究者都在对基于字符串匹配方法进行优化，比如最大长度设定、字符串存储和查找方式以及对于词表的组织结构，比如采用TRIE索引树、哈希索引等。但汉语语言现象复杂丰富，词典的完备性、规则的一致性等问题使其难以适应开放的大规模文本的分词处理。*
>

#### 2.1.2 基于统计的机器学习方法

> *&emsp;&emsp;上下文中相邻的字同时出现的次数越多，就越可能构成一个词。因此该方法以字与字相邻出现的概率或频率来反映词的可信度。*

- **隐马尔可夫模型（HMM）**

  &emsp;&emsp;它用来描述一个含有隐含未知参数的马尔可夫过程。当遇到的问题满足基于序列和问题包含观测序列以及状态序列时，一般尝试使用HMM模型来解决问题。

  &emsp;&emsp;对于HMM模型，首先我们假设$Q$是所有可能的隐藏状态的集合，$V$是所有可能的观测状态的集合，即：
  $$
  Q={q_1,q_2,...,q_N},V={v_1,v_2,...v_M}
  $$
  &emsp;&emsp;其中，$N$是可能的隐藏状态数，$M$是所有的可能的观察状态数。

  &emsp;&emsp;对于一个长度为$T$的序列，$I$对应的状态序列, $O$是对应的观察序列，即：
  $$
  I={i_1,i_2,...,i_T},O={o_1,o_2,...o_T}
  $$
  &emsp;&emsp;其中，任意一个隐藏状态$i_t∈Q$,任意一个观察状态$o_t∈V$

  &emsp;&emsp;HMM模型做了两个很重要的假设如下：

  &emsp;&emsp;1） 齐次马尔科夫链假设。即任意时刻的隐藏状态只依赖于它前一个隐藏状态。如果在时刻$t$的隐藏状态是$i_t=q_i$,在时刻$t+1$的隐藏状态是$i_{t+1} =q_j$, 则从时刻$t$到时刻$t+1$的HMM状态转移概率$a_{ij}$可以表示为：
  $$
  a_{ij}=P(i_{t+1}=q_j|i_t=q_i)
  $$
  &emsp;&emsp;这样$aij$可以组成马尔科夫链的状态转移矩阵$A$:
  $$
  A=[a_{ij}]_{N×N}
  $$
  &emsp;&emsp;2） 观测独立性假设。即任意时刻的观察状态只仅仅依赖于当前时刻的隐藏状态。如果在时刻$t$的隐藏状态是$i_t=q_j$, 而对应的观察状态为$o_t=v_k$, 则该时刻观察状态$v_k$在隐藏状态$q_j$下生成的概率为$b_j(k)$满足：
  $$
  b_j(k)=P(o_t=v_k|i_t=q_j)
  $$
  &emsp;&emsp;这样$b_j(k)$可以组成观测状态生成的概率矩阵$B​$:
  $$
  B=[b_j(k)]_{N×M}
  $$
  &emsp;&emsp;除此之外，我们需要一组在时刻$t=1$的隐藏状态概率分布$Π$:
  $$
  Π=[π(i)]_N 其中π(i)=P(i_1=q_i)
  $$
  &emsp;&emsp;一个HMM模型，可以由隐藏状态初始概率分布$Π$, 状态转移概率矩阵$A$和观测状态概率矩阵$B$决定。$Π,A$决定状态序列，$B$决定观测序列。因此，HMM模型可以由一个三元组$λ$表示如下：
  $$
  λ=(A,B,Π)
  $$

- **条件随机场（CRF）**

  &emsp;&emsp;CRF是最大熵模型的sequence扩展、HMM的conditional求解，避免了label bias的问题。假设标注序列$Y$在给定观察序列XX的条件下，$Y​$构成的图为一个MRF，即可表示成图：

  <img src="https://github.com/natsuRen/img/blob/master/img/CRF.png?raw=true" style="zoom:20">

  &emsp;&emsp;最大熵模型与马尔可夫随机场（MRF）所对应factor graph都满足这样的因子分解：
  $$
  P(\vec{v})=\frac{∏_CΨ_C(\vec{v_C})}{Z}
  $$
  &emsp;&emsp;其中，$C$为图的团（即连通子图），$Ψ_C$为势函数。

  &emsp;&emsp;由此，可推导出条件概率：
  $$
  P(Y|X)=\frac{∏_jΨ_j(\vec{x},\vec{y})}{Z(\vec{x})}
  $$
  &emsp;&emsp;同最大熵模型一样，因子$Ψ_j(\vec{x},\vec{y})$亦可以写成特征函数的exp形式：
  $$
  Ψ_j(\vec{x},\vec{y})=exp(\sum_iλ_if_i(y_{j−1},y_j,\vec{x}))
  $$
  &emsp;&emsp;那么，CRF建模的式子可改写为:
  $$
  P(Y|X)=\frac{exp(\sum_{i,j}λ_if_i(y_{j−1},y_j,\vec{x}))}{Z(x→)}=\frac{1}{Z(\vec{x})}\prod_{j}exp(\sum_{i}λ_if_i(y_{j−1},y_j,\vec{x}))
  $$

- **支持向量机（SVM）**

  &emsp;&emsp;SVM的基本模型是在特征空间上找到最佳的分离超平面使得训练集上正负样本间隔最大。SVM是用来解决二分类问题的有监督学习算法，在引入了核方法之后SVM也可以用来解决非线性问题。 

  &emsp;&emsp;一般SVM有下面三种：

  &emsp;&emsp;1）硬间隔支持向量机（线性可分支持向量机）：当训练数据线性可分时，可通过硬间隔最大化学得一个线性可分支持向量机。

  &emsp;&emsp;2）软间隔支持向量机：当训练数据近似线性可分时，可通过软间隔最大化学得一个线性支持向量机。

  &emsp;&emsp;3）非线性支持向量机：当训练数据线性不可分时，可通过核方法以及软间隔最大化学得一个非线性支持向量机。

> &emsp;&emsp;*常见的分词器都是使用机器学习算法和词典相结合，一方面能够提高分词准确率，另一方面能够改善领域适应性。*
>
> *&emsp;&emsp;随着深度学习的兴起，也出现了基于神经网络的分词器，例如有人员尝试使用双向LSTM+CRF实现分词器，其本质上是序列标注，所以有通用性，命名实体识别等都可以使用该模型，据报道其分词器字符准确率可高达97.5%。该模型首先对语料进行字符嵌入，将得到的特征输入给双向LSTM，然后加一个CRF就得到标注结果，如下图所示：*
>
> <img src="https://github.com/natsuRen/img/blob/master/img/LSTM CRF.jpg?raw=true" style="zoom:20">

#### 2.1.3  现有分词工具

- **结巴分词**

  &emsp;&emsp;与采用分词模型Bigram + HMM 的ICTCLAS 相类似，Jieba采用的是Unigram + HMM。Unigram假设每个词相互独立，则分词组合的联合概率：
  $$
  P(c^n_1)=P(w^m_1)=\prod_iP(w_i)
  $$
  &emsp;&emsp;在Unigram分词后用HMM做未登录词识别，以修正分词结果。

  

  &emsp;&emsp;Jieba涉及到的算法有：

  &emsp;&emsp;1）基于Trie树结构实现高效的词图扫描，生成句子中汉字所有可能成词情况所构成的有向无环图。

  &emsp;&emsp;2）采用了动态规划查找最大概率路径, 找出基于词频的最大切分组合。

  &emsp;&emsp;3）对于未登录词，采用了基于汉字成词能力的HMM模型，使用了Viterbi算法。

  &emsp;&emsp;Jieba支持三种分词模式：

  &emsp;&emsp;1）精确模式：试图将句子最精确地切开，适合文本分析。

  &emsp;&emsp;2）全模式：把句子中所有的可以成词的词语都扫描出来, 速度非常快，但是不能解决歧义问题。

  &emsp;&emsp;3）搜索引擎模式：在精确模式的基础上，对长词再次切分，提高召回率，适合用于搜索引擎分词。

- **ICTCLAS**

  &emsp;&emsp;ICTCLAS本质上就是一个Bigram的Word-Based Generative Model，用HMM来做未登录词识别（修正分词）与词性标注。Biagram语法模型对应于1阶Markov假设，则ICTCLAS分词模型的联合概率为
  $$
  P(w^m_1)=\prod_iP(w_i|w_{i−1})
  $$
  &emsp;&emsp;ICTCLAS分词流程如下：

  &emsp;&emsp;1）按照核心词典进行第一次切词；

  &emsp;&emsp;2）在第一次切词的基础上，求解最大联合概率，作者称之为“二元切分词图”；

  &emsp;&emsp;3）HMM识别未登录词，诸如：人名、翻译人名、地名、机构名等；

  &emsp;&emsp;4）分词结果整理，词性标注。

- **THULAC**

  &emsp;&emsp;THULAC所采用的分词模型为结构化感知器（SP），属于两种CWS模型中的Character-Based Model，将中文分词看作为一个序列标注问题：对于字符序列$C=c{^1_n}$，找出最有可能的标注序列$Y=y{^1_n}$。定义score函数$S(Y,C)$为在$C$的情况下标注序列为$Y$的得分。SP以最大熵准则建模score函数，分词结果则等同于最大score函数所对应的标注序列。记在时刻t的状态为y的路径$y{^t_1}$所对应的score函数最大值为：
  $$
  δ_t(y)=maxS(y{^{t−1}_1},C,y_t=y)
  $$
  &emsp;&emsp;那么，则有递推式
  $$
  δ_{t+1}(y)=maxy′ {δ_t(y′)+w_{y′,y}+F(y_{t+1}=y,C)}
  $$
  &emsp;&emsp;其中，$w_{y′},y$为转移特征$(y′,y)$所对应的权值，$F(y_{t+1}=y,C)​$为特征模板的特征值的加权之和：
  $$
  F(y_{t+1}=y,C)=\sum_{i=1}^7α_if_i(y_{t+1}=y,C)
  $$
  &emsp;&emsp;其中，$α_i$为特征$f_i(y_{t+1}=y,C)$所对应的权重。

- **LTP**

  &emsp;&emsp;LTP是哈工大开源的一套中文语言处理系统，涵盖了基本功能：分词、词性标注、命名实体识别、依存句法分析、语义角色标注、语义依存分析等。其分词流程与其他分词器别无二致，先提取字符特征，计算特征权重值，然后Viterbi解码。

  &emsp;&emsp;同THULAC一样，LTP也是基于结构化感知器（SP），以最大熵准则建模标注序列$Y$在输入序列$X$的情况下的score函数：
  $$
  S(Y,X)=\sum_sα_sΦ_s(Y,X)
  $$
  &emsp;&emsp;其中，$Φ_s(Y,X)$为本地特征函数。中文分词问题等价于给定$X$序列，求解score函数最大值对应的$Y$序列：
  $$
  argmaxYS(Y,X)
  $$

- **性能对比**

  &emsp;&emsp;下面将上面四款国内代表分词软件进行了性能比较（数据来源：THULAC）。选择Windows作为测试环境，根据第二届国际汉语分词测评发布的国际中文分词测评标准，对不同软件进行了速度和准确率测试。

  msr_test（560KB）

  | Algorithm       | Time  | Precision | Recall |
  | --------------- | ----- | --------- | ------ |
  | LTP-3.2.0       | 3.21s | 0.867     | 0.896  |
  | ICTCLAS(2015版) | 0.55s | 0.869     | 0.914  |
  | jieba           | 0.26s | 0.814     | 0.809  |
  | THULAC          | 0.62s | 0.877     | 0.899  |

  pku_test（510KB）

  | Algorithm       | Time  | Precision | Recall |
  | --------------- | ----- | --------- | ------ |
  | LTP-3.2.0       | 3.83s | 0.960     | 0.947  |
  | ICTCLAS(2015版) | 0.53s | 0.939     | 0.944  |
  | jieba           | 0.23s | 0.850     | 0.784  |
  | THULAC          | 0.51s | 0.944     | 0.908  |

  CNKI_journal.txt（51 MB）

  | Algorithm       | Time     | Speed       |
  | --------------- | -------- | ----------- |
  | LTP-3.2.0       | 348.624s | 149.80KB/s  |
  | ICTCLAS(2015版) | 106.461s | 490.59KB/s  |
  | jieba           | 22.5583s | 2314.89KB/s |
  | THULAC          | 42.625s  | 1221.05KB/s |

### 2.2 向量化

#### 2.2.1 词袋模型

- **One-hot Representation**

  &emsp;&emsp;最早的一种比较直观的词向量生成方式，它通过先将语料库中的所有词汇汇总的得到N个词汇，并将语料库中的每个文档个体生成一个N维的向量，在每个维度就体现了该文档中存在多少个特定词汇，也就是向量中每一个元素都关联着词库中的一个单词，指定词的向量表示为：其在向量中对应的元素设置为1，其他的元素设置为0。

  &emsp;&emsp;这种方式是一种较为简单的映射方式，其产生的向量表示体现了词频的信息，但会产生长句子和短句子的向量长度不一致的情况，无法对向量做比较。

- **TF-IDF模型**

  &emsp;&emsp;在这种方式中，首先对词频进行了归一化，即使用词出现的频率而非次数代表词频，表示为公式如下：
  $$
  tf_{ij}=\frac{n_{ij}}{(Σ_k n_{ij} )}
  $$
  &emsp;&emsp;另一处改进为统计了每个词的逆文档频率指标，并使用该指标作为词罕见程度的度量值，以更好地刻画文档的生成向量。逆文档频率的模型如下：
  $$
  idf_i=lg \frac{|D|}{|\{j:t_k∈d_j\}|}
  $$
  &emsp;&emsp;这两种模型的共同的缺点在于其二者的向量长度都非常大，对于一个有着30W词汇量的语料，每个文档的映射向量长度将都是30W，这意味着产出的矩阵非常稀疏，并且在计算时也会非常复杂。

- **潜语义分析模型**

  &emsp;&emsp;这种模型通过数学方法，将文档之间的关系、词之间的关系和文档与词之间的关系都纳入考虑中。它把词和文档都映射到一个潜在语义空间，文档的相似性在这个空间内进行比较。

  &emsp;&emsp;具体来讲，潜语义分析模型使用了主成分分析的方式来进行降维，即通过抽取向量空间内分布方差最大的若干个正交方向来作为最后的表示方向，并对其余的方向的内容进行丢弃即得到了每个样本的低维表示，该表示是有损的，即丢失了在丢失维度上的分布细节。

  &emsp;&emsp;潜语义分析模型将这种将高维的向量表示转换为低维的向量表示的方法解释为文档的词向量空间转化为语义级别的向量空间，由此实现了一个有意义的文本降维的工作，即在更低维度上，一个维度并不再代表原来的一个词的信息，而是代表原来的几个词的一个混合信息，这被称为“语义维度”。被丢弃的维度上的分布也被认定为是一种“噪音”，对其丢弃可以更好地使用低维度的信息来表达原文本的语义信息。

> &emsp;&emsp;*上述的模型均为词袋模型，其基本的特点即为忽略了文本信息中的语序信息，即不考虑段落中的词汇顺序，仅将其反映为若干维度的独立概念，这种情况有着因为模型本身原因而无法解决的问题，比如主语和宾语的顺序问题，词袋模型天然无法理解诸如“我为你鼓掌”和“你为我鼓掌”两个语句之间的区别。因此基于上述模型的文本模型无法获取到原文本中语序所带来的信息。*
>
> <img src="https://github.com/natsuRen/img/blob/master/img/02.png?raw=true" style="zoom:20">

#### 2.2.2  基于神经网络的模型

- **神经网络语言模型（NNLM）**

  &emsp;&emsp;NNLM直接从语言模型出发，将模型最优化的过程转换为求词向量表示的过程，即通过一个三层的神经网络、SoftMax分类及反向传播算法实现了词向量的映射。在这种映射中，词向量本身包含了语义的信息，即通过向量的分布信息可以得知其对应词的相互联系，其基本结构如下图所示：

  <img src="https://github.com/natsuRen/img/blob/master/img/NNLM.png?raw=true" style="zoom:20">

  &emsp;&emsp;NNLM的输入层由中心词附近的多个词的向量表示，然后将这些向量进行拼接、tanh处理后得到隐藏层，最后通过SoftMax分类器得到输出层，即可获得所需概率向量。

- **word2vec**

  > &emsp;&emsp;*word2vec是Google在2013年开源的一款将词表征为实数值向量的高效工具，采用的模型有CBOW和Skip-Gram 两种。word2vec通过训练，可以把对文本内容的处理简化为K维向量空间中的向量运算，而向量空间上的相似度可以用来表示文本语义上的相似度。*
  >
  > &emsp;&emsp;*它采用一个三层的神经网络，训练的时候按照词频将每个词语Huffman编码，词频越高的词语对应的编码越短。这三层的神经网络本身是对语言模型进行建模，但同时获得一种单词在向量空间的表示。与潜在语义分析、潜在狄立克雷分配的经典过程相比，word2vec利用了词的上下文，语义信息更加丰富。*

  &emsp;&emsp;1）CBOW模型的主要思想是使用中心词附近的词去预测中心词，也就是说，CBOW模型的输入是某个词A周围的n个单词的词向量之和，输出是词A本身的词向量。训练流程如下：

  <img src="https://github.com/natsuRen/img/blob/master/img/cbow.jpg?raw=true" style="zoom:60">

  &emsp;&emsp;2）Skip-gram模型主要是使用中心词去预测中心词附近的词，也就是说，Skip-gram模型的输入是词A本身，输出是词A周围的n个单词的词向量。训练流程如下：

  <img src="https://github.com/natsuRen/img/blob/master/img/skip-gram.jpg?raw=true" style="zoom:50">

  &emsp;&emsp;CBOW与Skip-gram的区别主要在于CBOW模型某种意义上属于一种词袋模型，一定程度上忽略了文本的语序顺序，并且由于模型结构的不同，其二者反向传播进行参数调整的方式不同：CBOW模型的中心词会共享一次反向传播的梯度下降，而Skip-gram则不存在这种共享关系。

- **doc2vec**

  > &emsp;&emsp;*由于word2vec只是基于词的维度进行“语义分析”的，不具有上下文的“语义分析”能力。因此基于上述的Word2Vec的方法，Quoc V. Le  和 Tomas Mikolov又给出了Doc2Vec的训练方法*。

  1）DM

  &emsp;&emsp;DM算法大致上沿用了word2vec中CBOW的方法，即通过一个单层的神经网络结构来建立模型，在这个模型的训练过程中得到副产物段落向量，其不同点在于在这里另外增加了一个向量作为段落的向量表示，与词向量共同拼接或加和作为输入进入网络，网络通过梯度下降的方式进行优化，当需要给出一个新的段落向量表示时，在预测阶段，模型的参数（包括词向量和模型中的SoftMax参数）都是固定的。

  <img src="https://github.com/natsuRen/img/blob/master/img/03.png?raw=true" style="zoom:40">

  2）DBOM

  &emsp;&emsp;DBOM算法大体上也是沿用了Word2vec中的Skip-gram的方法，即以文档向量作为输入，以最大化输出为文档中的词作为目标进行训练，这种方式也可以获得文档的向量表示。

  <img src="https://github.com/natsuRen/img/blob/master/img/04.png?raw=true" style="zoom:50">

> *由此可见，基于神经网络的文本向量化方式的特点主要包括以下几个：*
>
> &emsp;&emsp;*1）基于神经网络的文本向量化方式可以更多地利用激活函数及SoftMax函数中的非线性特点，这种特点为模型带来了更多的拟合能力，使得模型可以学习到更多的文本特性，生成的文本向量是更好地文本向量化表示。* 
>
> &emsp;&emsp;*2）基于神经网络的文本向量化方式很大程度上保留了语序信息，其利用了文本相邻的特性，这种特点在词袋模型中往往是直接忽略掉了的。* 
>
> &emsp;&emsp;*3）基于神经网络的模型在语料规模和训练复杂度上也有着更高的要求，这意味着只有在计算能力和文本数据量达到一定程度的时候才可以开展。*

### 2.3 相似度算法

#### 2.3.1 余弦相似度

&emsp;&emsp;计算两个文本向量表示的余弦值，值越大越相似。假定$A$和$B$是两个$n$维向量，$A$是 $[A_1, A_2, ..., A_n] $，$B$是 $[B_1, B_2, ..., B_n] $，则$A$与$B$的夹角$θ$的余弦等于：
$$
cosθ=\frac{\sum^n_{i=1}(A_i×B_i)}{\sqrt{\sum^n_{i=1}(A_i)^2}×\sqrt{\sum{^n_{i=1}(B_i)^2}}}=\frac{A·B}{|A|×|B|}
$$
&emsp;&emsp;使用这个公式，我们就可以得到，句子$A$与句子$B$的夹角的余弦。余弦值越接近1，就表明夹角越接近0度，也就是两个向量越相似，这就叫"余弦相似性"。

#### 2.3.2 n-gram模型

&emsp;&emsp;N-gram 是一种基于统计语言模型的算法，又被称为一阶马尔科夫链。它的基本思想是将文本里面的内容按照字节进行大小为N的滑动窗口操作，形成了长度是N的字节片段序列。每一个字节片段称为gram，对所有的gram的出现频度进行统计，并且按照事先设定好的阈值进行过滤，形成关键gram列表，也就是这个文本的向量特征空间。列表中的每一种gram就是一个特征向量维度。可以通过计算得到两个句子的N-gram特征向量来进一步计算比较它们的相似性。
$$
p(W)=\prod_{i=1}^np (w_i│w_1…w_i-1)= \prod_{i=1}^np(w_i│w_(i-n+1)…w_{i-1} )
$$

#### 2.3.3 LSTM

&emsp;&emsp;作为处理时间序列数据上具有优势的序列模型，循环神经网络（RNN）能够处理可变长度的输入序列并且挖掘序列中的依赖关系。但是由于RNN自身存在误差消失的问题，不能很好地学习较长范围内的序列依赖信息，因此有研究者就这个问题提出一种基于RNN的变种，长短期记忆网络（LSTM）模型。

&emsp;&emsp;所有 RNN 都具有一种重复神经网络模块的链式的形式。在标准的 RNN 中，这个重复的模块只有一个非常简单的结构，例如一个 tanh 层。

<img src="https://github.com/natsuRen/img/blob/master/img/RNN.webp?raw=true" style="zoom:40">

&emsp;&emsp;LSTM 同样是这样的结构，但是重复的模块拥有一个不同的结构。不同于 单一神经网络层，这里是有四个，以一种非常特殊的方式进行交互。

<img src="https://upload-images.jianshu.io/upload_images/42741-b9a16a53d58ca2b9.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1000/format/webp" style="zoom:40">

<img src="https://upload-images.jianshu.io/upload_images/42741-ea943b818b8e18d0.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/950/format/webp" style="zoom:40">



#### 2.3.4 **卷积神经网络**

- **概要简介**

  &emsp;&emsp;卷积神经网络(CNN)的最大的功能在于对于复杂对象的特征提取并且高效的分类方式，所以同时适用于文本相似度分析和文本特征提取。CNN一般可以分为两个部分，特征提取层和特征映射层。其中，在文本相似度的应用上详细分为输入层，卷积层，池化层,连接层和输出层。

  <img src="https://github.com/natsuRen/img/blob/master/img/05.png?raw=true" style="zoom:40">

  &emsp;&emsp;利用word2vec可以实现词向量的表示，那么就可以把句子表示为用矩阵表示的数据结构。那么，类似于用CNN做图像识别一样，将得到的两个句子的二维矩阵来进行特征提取，二维矩阵作为输入，就可以用卷积层和池化层来进行特征提取和分类，从而得到文本相似度的结果。

- **详细过程**

  &emsp;&emsp;CNN在实现文本相似度分析一共分为四层，分别是输入层，卷积层，池化层和输出层。由于文本分析主要是通过判断词语之间的相似度来实现句子的相似度，所以不需要过多的步骤，下面详细介绍各层的构建。

  &emsp;&emsp;1）输入层：利用Word2vec来实现词向量的构建，这里主要讲解python中对于Google的word2vec的skim-gram词向量模型的实现模块。输入相应的分词文本，该模型就自动构建该文本的模型。项目的文本构建如下图所示：

  <img src="https://github.com/natsuRen/img/blob/master/img/06.png?raw=true" style="zoom:80">

  &emsp;&emsp;2）卷积层：主要是实现特征的选取，通过一个卷积核来扫描输入层的矩阵，卷积核的大小就是作为扫描的感受野，防止越界。文本相似度计算选择一个2*2的卷积核，和CNN做图像识别不同的就是卷积核的数量，因为文本相似度分析主要是找出相似度最高的，所以选择一个卷积核就能达到目的,多个卷积核反而会降低效果。详细的计算过程如下图所示：

  <img src="https://github.com/natsuRen/img/blob/master/img/CNN.gif?raw=true" style="zoom:30">

  &emsp;&emsp;3）池化层：主要是实现丢弃一些实在不相关的数据，一般采用两种方法实现，第一种max-pooling，第二种average-pooling。因为文本相似度计算需要的是相似度高的数据，所以选择max-pooling。和卷积层相似，不同在于池化层只对矩阵本身进行运算。

  &emsp;&emsp;4）输出层：输出层主要实现卷积层和池化层的连接，经过多次卷积层和池化层的循环，最后实现几个动态的值来表示该文本的相似度，简单地求平均就可以得到一个表示相似度的值。

  

> &emsp;&emsp;*大多学者将文本相似度计算方法分为基于统计或者语料库的方法和基于世界知识的方法,但这种分类忽略了基于字符串和句法分析等重要算法,且近年来有新的方法出现,所以这里我们对分类体系进行了扩展和细分,如下所示：*
>
> <img src="https://github.com/natsuRen/img/blob/master/img/07.png?raw=true" style="zoom:30">

- **基于字符串的代表方法**

  | 方法                  | 基本思想                                                     | 类型     | 特点与不足                                                   |
  | --------------------- | ------------------------------------------------------------ | -------- | ------------------------------------------------------------ |
  | 编辑距离              | $S_A$转换到 $S_B$需要删除、插入、替换操作的最少次数。        | 字符组成 | 计算准确，但费时。                                           |
  | 汉明距离              | $1-\frac{(\sum^n_{k=1}x_k\bigoplus{y_k})}{n}$$x_k​$、$y_k​$分别表示字符串$S_A​$、$S_B​$对应码第K位的分量。 | 字符顺序 | 采用模2加运算，简化长文本计算,效率高。                       |
  | LCS                   | 共现且最长的子字符串                                         | 字符顺序 | 原理简单，针对派生词和短文本有较好效果，但不适用于长文本。   |
  | Jaro-Winkler          | $d_j=\frac{1}{3}(\frac{m}{|s_A|}+\frac{m}{|S_B|}+\frac{(m-t)}{m})$，其中m是匹配的字符数，t是换位的数目。相似度计算公式为$d_j+(lp(1-d_j))$，其中$d_j$是两个字符串的Jaro距离，$l$是前缀相同的长度，规定最大为4.Winkler将p定义为0.1 | 字符顺序 | }   考虑了前缀相同的重要性，针对短文本有较好效果，但不适用于长文本。 |
  | N-gram                | $\frac{相似的n元组数量}{n元组总量}$                          | 集合思想 | n可调，方法较灵活，但不适用于长文本。                        |
  | 余弦相似度            | $\frac{\vec{S_A}\vec{S_B}}{||S_A||*||S_B||}$                 | 词语组成 | 将文本至于向量空间，解释性强，较为常用，但不适用于长文本。   |
  | Dice系数              | $\frac{2×comm(S_A,S_B)}{leng(S_A)+leng(S_B)}$                | 词语组成 |                                                              |
  | 欧式距离              | $\sqrt{S_A^2+S^2_B}$                                         | 词语组成 | 算法简单直接，但效果粗糙，不适用于长文本                     |
  | Jaccard               | $\frac{S_A\bigcap{S_B}}{S_A\bigcup{S_B}}$                    | 集合思想 | 不适用于长文本                                               |
  | Overlap   Coefficient | $\frac{S_A\bigcap{S_B}}{min(S_A,S_B)}$                       | 集合思想 | 当一个字符串是零一字符串的子字符串时，相似度很大。           |

- **基于词袋模型的代表方法**

  | 方法 | 基本思想                                                     | 类型 | 特点与不足                                                   |
  | ---- | ------------------------------------------------------------ | ---- | ------------------------------------------------------------ |
  | VSM  | 将每篇文档表示成一个基于词频或者词频–逆文档频率权重的实值向量（特征项），然后采用余弦相似度算法计算相似度。 | 文本 | 原理简单，但当文本中的特征项较多时，产生的高维稀疏矩阵会导致计算效率不高。而且，向量空间模型算法的假设是文本中抽取的特征项没有关联,不符合文本语义表达。 |
  | LSA  | 将文本从稀疏的高维词汇空间映射到低维的潜在语义空间,在潜在语义空间计算相似性。 | 文本 | 基于VSM，计算准确度较高，但算法复杂度高，可移植性差。        |
  | LDA  | $p_j(w_i|d_s)=p(w_i|t_j)*p(t_j|d_s)$，其中$t_j$代表文档$d_s$中的第$i$个单词$w_i$所对应的topic。 | 文本 | 适用于大规模文本及，鲁棒性较高，保证了文本的语义性。         |

- **基于神经网络的代表方法**

  | 方法     | 基本思想                                                     | 类型     | 特点与不足                                                   |
  | -------- | ------------------------------------------------------------ | -------- | ------------------------------------------------------------ |
  | WMD      | 在词向量空间里计算将文档中所有的词移动到另一文档对应的词需要的小移动距离。 | 词向量   | 原理简单，但不适用于大规模文本。                             |
  | S-WMD    | 在WMD基础上加入新文档特征“re-weighting”和新移动代价“metric A”。 | 词向量   | 基于WMD，仅适用于可监督的文本。                              |
  | Jaccard  | $Sim(S,T)=\frac{||Inter(S,T)||}{||Union(S,T)||}$ 其中Inter(S,T)，Union(S,T)分别表示句子$S、T$的词汇交集和词汇并集。 | 词向量   | 准确率较高，但对于中文文本适用效果不如英文文本。             |
  | LSF-SCNN | 利用词汇语义特征技术计算输入的问题和候选答案的每个单词的LSF特征值，然后将LSF特征与词嵌入拼接构成的句子矩阵经过条约卷积层和K-max均值采样层形成对应与问题和答案向量表达$X_q$和$X_a$。最后将$X_q$、$X_a$以及由$X_q$、$X_a$根据学习得到的相似度分数整合作为分类器的输入，最终获得文本相似度的值。 | 文本向量 | 准确率较高，整合了LSF、SC、KMA三种技术，提升了模型的整体效果。 |

## 第三章 概要设计

### 3.1 预处理

#### 3.1.1 数据扩展

> &emsp;&emsp;*百度研究院发布的一项大规模研究报告就表明，随着训练数据的增多，深度学习模型的准确率也有可预期的提高。通过实际实验，百度研究院的研究员们发现，只要有足够的训练数据和计算资源，那么训练大模型时随着规模提升带来的准确率提升就是可以预期的。在百度研究院研究的机器翻译、语言建模、图像分类、语音识别四个应用领域中，在众多的顶尖模型上都能看到这样的结果。* 

&emsp;&emsp;因此，我们选择在已有数据基础上，利用以下两种方法扩大训练数据量，为更高的相似度计算精准度做准备：

- **百度爬取数据**

  &emsp;&emsp;编写程序自动获取已有用户标准问题，根据标准问爬取百度知道相关页面的问题序列，并以此作为新的用户问题数据。

- **数据排列组合**

  &emsp;&emsp;1）扩充正样本：首先将现有训练集按照标准问分类，然后将同类中的数据进行排列组合。最后，合并各个类并去除重复项后，统一给每条数据打标签（label = 1）。

  &emsp;&emsp;2）扩充负样本：首先将现有训练集按照标准问分类，然后将不同类中的数据进行排列组合。最后，合并各个类并去除重复项后，统一给每条数据打标签（label = 0）。

#### 3.1.2 数据清洗

> &emsp;&emsp;*数据清洗， 是整个数据分析过程中不可缺少的一个环节，其结果质量直接关系到模型效果和最终结论。*

- **去无用字符**

  &emsp;&emsp;去除数字、标点、字母、空格等字符，使文本只保留汉字字符。在Java和Python中，均可使用.replace(“ ”,” ”)函数去除文本中的空格或用正则表达式.compile("[\^\u4E00-\u9FA5]")，去掉数字、标点、字母等。

- **去停用词**

  &emsp;&emsp;文档中如果大量使用Stop words容易对页面中的有效信息造成噪音干扰，所以在文本相似度计算之前都要对文本信息进行消除噪音的处理。

  &emsp;&emsp;首先创建停用词list，例如stop_words.txt（stop_words. txt包括标点、特殊符号和中文停用词等），再根据停用词list删去文本中的停用词。

- **中文纠错**

  &emsp;&emsp;中文纠错分为以下两步：

  &emsp;&emsp;1）错误检测：先通过结巴中文分词器切词，由于句子中含有错别字，所以切词结果往往会有切分错误的情况，这样从字粒度和词粒度两方面检测错误，语言模型困惑度（PPL）检测某字的似然概率值低于句子文本平均值，或切词后不在词典中，则判定该字是疑似错别字的概率大。整合这两种粒 度的疑似错误结果，形成疑似错误位置候选集；

  &emsp;&emsp;2）错误纠正：遍历所有的疑似错误位置，并使用音似、形似词典替换错误位置的词，然后通过语言模型计算句子困惑度，对所有候选集结果比较并排序，得到最优纠正词。

  &emsp;&emsp;可以使用spelling_corrections.json实现纠错及部分同义词替换功能。

#### 3.1.3 jieba分词

&emsp;&emsp;根据实际情况分析，我们使用jieba的精确模式来对用户输入的文本进行分词。虽然 jieba 有新词识别能力，但依然存在识别不出新词导致分词不正确的情况。因此我们可以载入自定义的词典，其中包含jieba默认词库里没有的专业词，以便更加精准地分词。

&emsp;&emsp;用法：jieba.load_userdict(file_name) # file_name 为文件类对象或自定义词典的路径。词典格式和 dict_all.txt 一样，一个词占一行；每一行分三部分：词语、词频（可省略）、词性（可省略），用空格隔开，顺序不可颠倒。file_name 若为路径或二进制方式打开的文件，则文件必须为 UTF-8 编码。词频省略时使用自动计算的能保证分出该词的词频。（注意：自定义词典不要用Windows记事本保存，这样会加入BOM标志，导致第一行的词被误读）

#### 3.1.4 向量化

- **TF-IDF**

- **CBOW**

### 3.2 特征提取

- **两个语句的长度上的差距**

  &emsp;&emsp;分词处理、去停用词等预处理后两个句子的长度差。

- **两个语句的编辑距离**

  &emsp;&emsp;编辑距离指将一个字符串转换成另一个字符串的最少操作数（插入、删除和替换），即根据预处理后两个句子中一个句子转换成另一个句子所需步数来衡量相似性（对词进行操作）。扩展的编辑距离增加一种操作，相邻字符的交换（实际为相邻词的交换）。通过计算得到的距离除以长度较大的句子的长度得到的值作为特征。

- **两个语句的n-gram相似性的特征**

  &emsp;&emsp;N-gram 是一种基于统计语言模型的算法，又被称为一阶马尔科夫链。它的基本思想是将文本里面的内容按照字节进行大小为N的滑动窗口操作，形成了长度是N的字节片段序列。每一个字节片段称为gram，对所有的gram的出现频度进行统计，并且按照事先设定好的阈值进行过滤，形成关键gram列表，也就是这个文本的向量特征空间。列表中的每一种gram就是一个特征向量维度。可以通过计算得到两个句子的N-gram特征向量来进一步计算比较它们的相似性。

- **两个语句的词的统计特征，包括相同词的个数，不同词的个数，Jaccard相似度**

  &emsp;&emsp;包括相同词和不同词的个数，可以利用Jaccard相似度估量，即两个句子的交集（相同词的数量）除以两个句子的并集（所有出现的不重复的词的数量）来得到两个句子的相似度。

- **两个语句中的疑问词的相似度，主要是根据疑问词相似度规则文件进行计算**

  &emsp;&emsp;疑问词的相似度主要是根据疑问词相似度规则文件（包含参与比较的疑问词的文件）进行计算，然后得到疑问词相同的比例来作为特征。

- **两个语句的词向量组合的相似度，主要是根据全部训练集做语料库使用word2vec训练的词向量计算的两个语句的词向量的组合相似度**

  &emsp;&emsp;根据全部训练集做语料库使用word2vec训练的词向量计算的两个语句的词向量的组合相似度，可以利用余弦相似度来衡量相似度。

- **两个语句神经网络编码的曼哈顿距离相似度和余弦相似度**

  &emsp;&emsp;主要是根据两个语句的预训练词向量输入经过LSTM进行编码计算出两个语句的语义向量的曼哈顿距离和余弦相似度作为最后的机器学习的分类模型特征之一。

- **两个语句的神经网络编码的match vector形式计算的相似度**

- **两个语句的神经网络编码的改进的Compare-Aggregate模型的相似度**	

### 3.3 模型设计

&emsp;&emsp;抽取的NLP统计特征和经过深度模型训练输出的语句的相似度,最终采用Stacking的集成学习方式进行训练。

## 第四章 详细设计

#### 4.1 预处理

##### 4.1.1 数据扩展

- **根据标准问题爬取相关URL**

  ```python
  def baidu_search(wd,pn_max,save_file_name):
  #百度搜索爬虫，给定关键词和页数以及存储到哪个文件中，返回结果去重复后的url集合
      url = "https://www.baidu.com/s"
      return_set = set()
      for page in range(pn_max):
          pn = page*10
          querystring = {"wd":wd,"pn":pn}
          headers = {
                  'pragma': "no-cache",
                  'accept-encoding': "gzip, deflate, br",
                  'accept-language': "zh-CN,zh;q=0.8",
                  'upgrade-insecure-requests': "1",
                  'user-agent': "Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/59.0.3071.115 Safari/537.36",
                  'accept': "text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8",
                  'cache-control': "no-cache",
                  'connection': "keep-alive",
                  }
          try:
              response = requests.request("GET", url, headers=headers, params=querystring)
              print("!!!!!!!!!!!!",response.url)
              #解析html
              selector = etree.HTML(response.text, parser=etree.HTMLParser(encoding='utf-8'))
          except Exception as e:
              print ("页面加载失败", e)
              continue
          
          with open(save_file_name,"a") as f:
              for i in range(1,10):
                  try:
                      #根据属性href筛选标签
                      context = selector.xpath('//*[@id="'+str(pn+i)+'"]/h3/a[1]/@href')
                      print(len(context),context[0])
                      
                      i = context[0]
                      f.write(i)
                      return_set.add(i)
                      f.write("\n")
  
                  except Exception as e:
                      print(i,return_set)
                      print("3",e)
      return return_set
  ```

- **根据URL获取网页标题**

  ```python
  #判断是否是英文，用于后期筛选数据
  def isEnglish(checkStr):
      for ch in checkStr:
          if u'\u4e00' <= ch <= u'\u9fff':
              flag = True
          else:
              flag = False
      return flag
  
  if __name__=='__main__':
      
      datafile = '../data/train.csv'
      data = pd.read_csv(datafile)
      y = data["知识库标准问"].values
      qes = list(sorted(set(y),key=list(y).index))
      
      socket.setdefaulttimeout(20)  # 设置socket层的超时时间为20s    
      
      br = mechanize.Browser()
      br.set_cookiejar(http.cookiejar.LWPCookieJar()) # Cookie jar
      
      br.set_handle_equiv(True) # Browser Option
      br.set_handle_gzip(True)
      br.set_handle_redirect(True)
      br.set_handle_referer(True)
      br.set_handle_robots(False)
      
      br.set_handle_refresh(mechanize._http.HTTPRefreshProcessor(), max_time=1)
      
      br.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')] 
    
      temp = 0
      docFiles = os.listdir(urlDir)    
      for j in range(len(docFiles)):
          read_file = open("../data/url/save_url" + str(j) + ".txt")
          write_file = xlwt.Workbook()
          table = write_file.add_sheet('data')
  
          table.write(0,0,qes[temp])
          print(str(temp) + '------' + qes[temp])
              
          i = 1
          for line in read_file:
              try:
                  br.open(line)               
                  text = br.title()
                  head,sep,tail = text.partition('_')
                  head,sep,tail = head.partition('|')
                  head,sep,tail = head.partition('-')
                  
                  if(isEnglish(head)):             
                      print(head)
                      table.write(i,0,head)
                      i += 1           
              
              except Exception as e:
                  print("ERROR",e)  
                  
              time.sleep(1)	
              
          write_file.save('H:/大三上/服务外包/省赛/data/url_data/save_data' + str(temp) + '.xls')
          temp += 1
          print('\n')
  ```

- **获取正样本Rtrain.csv**

  ```python
  x = data["客户提问"].values
  y = data["知识库标准问"].values
  
  for i in range(len(Rresult)):
      Rresult[i] = str(i) + '\t' + Rresult[i]
  
  dataframe1 = pd.DataFrame(Rresult,columns=None)
  dataframe1.to_csv("../data/Rresult.csv",index=False,encoding='utf_8_sig')
  ```

- **获取负样本Ftrain.csv**

  ```python
  Rresult0 = set(x + '\t' + y + '\t')#用于后续获取负样本
  Rresult = x + '\t' + y + '\t1'
  
  #打乱顺序后合并数据
  random.shuffle(x)
  random.shuffle(y)
  Fresult = set(x + '\t' + y + '\t')
  
  #删除正样本
  for row in Rresult0:
      if row in Fresult:
          Fresult.remove(row)
    
  Fresult = list(Fresult) 
  
  for i in range(len(Fresult)):
      Fresult[i] = Fresult[i] + '0'
      
  dataframe2 = pd.DataFrame(Fresult,columns=None)
  dataframe2.to_csv("../data/Fresult.csv",index=False,encoding='utf_8_sig')
  
  ```

- **获取二分类数据result_data.csv**

  ```python
  result = np.concatenate((Rresult,Fresult), axis=0)
  
  random.shuffle(result)
  
  for i in range(len(result)):
      result[i] = str(i) + '\t' + result[i]
   
  dataframe = pd.DataFrame(result,columns=None)
  dataframe.to_csv("../data/result_data.csv",index=False,encoding='utf_8_sig')
  ```

- **数据分类**

  ```python
  #计算数据一共有多少种类型flag以及每种类型的数据有多少个temp[i]
  flag = 0
  temp = []
  for i in range(len(y1) - 1):
      if y1[i] == y1[i + 1]:
          continue
      else:
          temp.append(i)
          flag += 1
  
  
  #同义数据归类 
  expand_data0 = []  
  expand_data0.append(y1[temp[0]])      
  for i in range(temp[0] + 1):
      expand_data0.append(x1[i])
  expand_dataframe0 = pd.DataFrame(expand_data0,columns=["问题"])
  expand_dataframe0.to_csv("../data/classification/classification_data0.csv",
                   index=False,encoding='utf_8_sig')
  
  expand_data = []
  for i in range(1,len(temp)):
      expand_data.append(y1[temp[i]])
      for j in range(temp[i - 1],temp[i]):
          expand_data.append(x1[j + 1])
      
      #将同义句放在一个csv文件中
      dataframe = pd.DataFrame(expand_data,columns=["问题"])
      dataframe.to_csv("../data/classification/classification_data" + str(i) + ".csv",
                       index=False,encoding='utf_8_sig')
      
      expand_data = [] 
  ```

- **扩充正样本**

  ```python
  for i in range(len(temp)):
     file = "../data/classification/classification_data" + str(i) + ".csv"
     edata = pd.read_csv(file)
     
     e1 = edata["问题"].values + '\t'
     e2 = e1 + '1' #label = 1
     e3 = []
     for j in e1:
         for k in e2:
             e3.append(j + k)
     
     dataframe = pd.DataFrame(e3,columns=None)
     dataframe.to_csv("../data/expand/R/ERresult_data" + str(i) + ".csv",
                      index=False,encoding='utf_8_sig')
  ```

- **扩充负样本**

  ```同理扩充正样本。```

- **合并数据**

  ```python
  Ffile0 = "../data/expand/F/EFresult_data0.csv"
  Eresult = Fedata0 = pd.read_csv(Ffile0)
  
  Flength = len(Fedata0)
  for i in range(0,len(temp) - 2):   
      Ffile = "../data/expand/F/EFresult_data" + str(i + 1) + ".csv"
      Fedata = pd.read_csv(Ffile)
      
      Eresult = np.concatenate((Eresult,Fedata), axis=0)
  
  for i in range(len(temp)):     
      Rfile = "../data/expand/R/ERresult_data" + str(i) + ".csv"
      Redata = pd.read_csv(Rfile)
      
      Eresult = np.concatenate((Eresult,Redata), axis=0)     
  
  Eresult = np.unique(Eresult)
  Eresult = random.sample(list(Eresult),len(Eresult))
  
  for i in range(len(Eresult)):
      Eresult[i] = str(i) + '\t' + Eresult[i]
   
  dataframe = pd.DataFrame(Eresult,columns=None)
  dataframe.to_csv("../data/final_data.csv",index=False,encoding='utf_8_sig')
  ```

- **正样本：负样本 =  60116：62160**

##### 4.1.2 数据清洗

- **加载数据（停用词/纠错词典/疑问词典）**

  ```python
  def load_stopwordslist(filepath):
      with io.open(filepath,"r",encoding="utf-8") as file:
          stop_words = [line.strip() for line in file]
          return stop_words
  def load_spelling_corrections(filepath)#同上
  def load_doubt_words(filpath)#同上
  ```

- **词替换**

  ```python
  def transform_other_word(str_text,reg_dict):
      for token_str,replac_str in reg_dict.items():
          str_text = str_text.replace(token_str, replac_str)
      return str_text
  
  def strip_why(rawq):
      rawq = re.sub('为什么|为何|为啥|为么|为撒|咋个|为什|怎么回事|是什么原因|什么原因', '', rawq)
      if re.match(r'怎么.*(不|没|了|只|会|又|要|老|总|才|是)',rawq):
          rawq = re.sub('怎么', '', rawq)
      return rawq
  
  def strip_how(rawq):
      rawq = re.sub('怎么办|咋办', '', rawq)
      return rawq
  ```

- **文本处理**

  ```python
  def preprocessing(data_df,fname):
      """
      :param data_df:需要处理的数据集
      :param fname:
      :return:
      """
      # 加载停用词
      stopwords = load_stopwordslist(project.aux_dir + stop_words_path)
      # 加载拼写错误替换词
      spelling_corrections = load_spelling_corrections(project.aux_dir + spelling_corrections_path)
  
      re_object = re.compile(r'\*+') #去除句子中的脱敏数字***，替换成一
      vocabs = defaultdict(int)# 记录词汇表词频
      for index, row in data_df.iterrows():
          # 每1000个打印一下句子的词向量
          if index != 0 and index % 2000 == 0:
              print("{:,}  {}-sentence embedding.".format(index,fname))
          # 分别遍历每行的两个句子，并进行分词处理
          for col_name in ["s1", "s2"]:
              # 替换掉脱敏的数字
              re_str = re_object.subn(u"十一",str(row[col_name]))
              # 纠正一些词
              spell_corr_str = transform_other_word(re_str[0],spelling_corrections)
              # 分词
              seg_str = seg_sentence(spell_corr_str, stopwords)
              for word in seg_str.split(" "):
                  vocabs[word] = vocabs[word] + 1
                  data_df.at[index, col_name] = seg_str
  
      data_df.to_csv(project.preprocessed_data_dir + '{}.csv'.format(fname), sep='\t', header=None,index=None,encoding='utf-8')
      project.save(project.preprocessed_data_dir + '{}.pickle'.format(fname),vocabs)
      del data_df
  ```

##### 4.1.3 jieba分词

```python
def seg_sentence(sentence,stop_words):
    """
    对句子进行分词
    :param sentence:句子，String
    """
    sentence_seged = jieba.cut(sentence.strip())
    out_str = ""
    for word in sentence_seged:
        if word not in stop_words:
            if word != " ":
                out_str += word
                out_str += " "
    return out_str
```

##### 4.1.4 向量化

```python
# 加载所有的词汇表训练集和测试集
pre_deal_train_df = pd.read_csv(project.preprocessed_data_dir + 'train_0.6_seg.csv',
                                names=["index", "s1", "s2", "label"],
                                header=None,encoding='utf-8',
                                sep='\t')
pre_deal_test_df = pd.read_csv(project.preprocessed_data_dir + 'test_0.4_seg.csv',
                                names=["index", "s1", "s2", "label"],
                                header=None,encoding='utf-8',
                                sep='\t',
                                )
texts = []
texts_s1_test = pre_deal_test_df['s1'].tolist()
texts_s2_test = pre_deal_test_df['s2'].tolist()

texts_s1_train = pre_deal_train_df['s1'].tolist()
texts_s2_train = pre_deal_train_df['s2'].tolist()

texts.extend(texts_s1_test)
texts.extend(texts_s2_test)
texts.extend(texts_s1_train)
texts.extend(texts_s2_train)

# 生成token词典
tokenizer.fit_on_texts(texts)

# 生成各个词对应的index列表
s1_train_ids = tokenizer.texts_to_sequences(texts_s1_train)
s2_train_ids = tokenizer.texts_to_sequences(texts_s2_train)

s1_test_ids = tokenizer.texts_to_sequences(texts_s1_test)
s2_test_ids = tokenizer.texts_to_sequences(texts_s2_test)

num_words_dict = tokenizer.word_index

# 训练集的词汇表的词向量矩阵,行数为最大值+1,形式为：index->vec
embedding_matrix = 1 * np.random.randn(len(num_words_dict) + 1, embedding_size)
embedding_matrix[0] = np.random.randn(embedding_size)

# 加载预训练的词向量w2v
print('load w2v_model...')
w2v_model = KeyedVectors.load_word2vec_format(w2v_path, binary=False)
print('finish w2v_model...')
```

#### 4.2 特征提取

##### 4.2.1 深度学习特征提取

​	包括三种，根据三个模型来进行特征提取。

- **神经网络编码的曼哈顿距离相似度和余弦相似度作为特征**

  ```python
  def extract_feature_siamese_lstm_manDist():
      # 前期参数设置
      embedding_matrix_file_path = 'train_all_w2v_embedding_matrix.pickle'
      feature_name = 'dl_siamese_lstm_manDist'
      RANOD_SEED = 42
      np.random.seed(RANOD_SEED)
      nepoch = 40
      num_folds = 5
      batch_size = 512
  
      # 加载Embeding矩阵
      embedding_matrix = project.load(project.aux_dir + embedding_matrix_file_path)
  
      #加载输入数据
      X_train_s1 = project.load(project.preprocessed_data_dir + 's1_train_ids_pad.pickle')
      X_train_s2 = project.load(project.preprocessed_data_dir + 's2_train_ids_pad.pickle')
  
      X_test_s1 = project.load(project.preprocessed_data_dir + 's1_test_ids_pad.pickle')
      X_test_s2 = project.load(project.preprocessed_data_dir + 's2_test_ids_pad.pickle')
  
      #y_0.6_train.pickle 存储的为list
      y_train = np.array(project.load(project.features_dir + 'y_0.6_train.pickle'))
      y_val =  np.array(project.load(project.features_dir + 'y_0.4_test.pickle'))
  
      #定义model param
      model_param = {
          'lstm_units':50,
          'lstm_dropout_rate':0.,
          'lstm_re_dropout_rate':0.,
          'desen_dropout_rate':0.75,
          'num_dense':128
      }
      # model_checkpoint_path = project.temp_dir + 'fold-checkpoint-'+feature_name + '.h5'
      kfold = StratifiedKFold(
          n_splits=num_folds,
          shuffle=True,
          random_state=RANOD_SEED
      )
      # 存放最后预测结果
      y_train_oofp = np.zeros((len(y_train),2),dtype='float64')
      y_test_oofp = np.zeros((len(X_test_s1),2),dtype='float64')
  
      train_y = to_categorical(y_train, 2)
      val_y = to_categorical(y_val,2)
  
      for fold_num, (ix_train, ix_val) in enumerate(kfold.split(X_train_s1,y_train)):
  
          # 选出需要添加的样本
          train_true_mask = y_train[ix_train] == 1
          X_train_true_s1 = X_train_s1[ix_train][train_true_mask]
          X_train_true_s2 = X_train_s2[ix_train][train_true_mask]
          y_train_true = train_y[ix_train][train_true_mask]
  
          # 进行添加
          X_add_train_fold_s1 = np.vstack([X_train_s1[ix_train],X_train_true_s2])
          X_add_train_fold_s2 = np.vstack([X_train_s2[ix_train],X_train_true_s1])
          y_add_train_fold = np.concatenate([train_y[ix_train],y_train_true])
  
  
  
          val_true_mask = y_train[ix_val]==1
          X_val_true_s1 = X_train_s1[ix_val][val_true_mask]
          X_val_true_s2 = X_train_s2[ix_val][val_true_mask]
          y_val_true = train_y[ix_val][val_true_mask]
  
          # 进行添加
          X_add_val_fold_s1 = np.vstack([X_train_s1[ix_val], X_val_true_s2])
          X_add_val_fold_s2 = np.vstack([X_train_s2[ix_val], X_val_true_s1])
          y_add_val_fold = np.concatenate([train_y[ix_val], y_val_true])
  
          print 'start train fold {} of {} ......'.format((fold_num + 1), 5)
          # 创建模型
          model = create_siamese_lstm_ManDistance_model(embedding_matrix, model_param)
          # 训练模型
          model_checkpoint_path = project.trained_model_dir + 'dl_siamese_lstm_manDist_model{}.h5'.format(fold_num)
          model.fit(x=[X_add_train_fold_s1,X_add_train_fold_s2],y=y_add_train_fold,
                        validation_data=([X_add_val_fold_s1,X_add_val_fold_s2],y_add_val_fold),
                        batch_size=batch_size,
                        epochs=nepoch,
                        verbose=1,
                        class_weight={0: 1, 1: 2},
                        callbacks=[
                            EarlyStopping(
                                monitor='val_loss',
                                min_delta=0.005,
                                patience=5,
                                verbose=1,
                                mode='auto'
                            ),
                            ModelCheckpoint(
                                model_checkpoint_path,
                                monitor='val_loss',
                                save_best_only=True,
                                save_weights_only=False,
                                verbose=1
                            )]
                    )
          model.load_weights(model_checkpoint_path)
          y_train_oofp[ix_val] = predict(model,X_train_s1[ix_val],X_train_s2[ix_val])
          K.clear_session()
          del X_add_train_fold_s1
          del X_add_train_fold_s2
          del X_add_val_fold_s1
          del X_add_val_fold_s2
          del y_add_train_fold
          del y_add_val_fold
          gc.collect()
  
      # save feature
  
      model_path = project.trained_model_dir + 'dl_siamese_lstm_manDist_model0.h5'
      model0 = load_model(model_path,
                      custom_objects={'ManDist': ManDist, 'fbeta_score': fbeta_score, 'precision': precision,
                                          'recall': recall})
      y_test_oofp = predict(model0,X_test_s1,X_test_s2)
      col_names = ['{}_{}'.format(feature_name,index) for index in range(2)]
      after_extract_feature_save_data(y_train_oofp,y_test_oofp,col_names,feature_name)
  ```

- **神经网络编码的match vector形式计算的相似度作为特征**

- **两个语句的神经网络编码的改进的Compare-Aggregate模型的相似度作为特征**

##### 4.2.2 NLP特征提取

&emsp;&emsp;这部对数据集（包括训练集train_data和测试集test_data）做特征提取，每行为两个句子s1和s2，对每一行的两个句子提取特征。主要步骤为载入数据，根据定义的函数提取特征，保存提取的特征。下面是公用的获取数据和保存特征的和函数。

```python
#获取train_data和test_data
def before_extract_feature_load_data(train_file,test_file):
    train_data = pd.read_csv(train_file,sep='\t', header=None, 
                                names=["index", "s1", "s2", "label"])
    test_data = pd.read_csv(test_file, sep='\t', header=None,
                                names=["index", "s1", "s2", "label"])
    return train_data,test_data
#保存提取的特征，包括训练集特征和测试集特征
def after_extract_feature_save_data(feature_train,feature_test,col_names,feature_name):
    project.save_features(feature_train, feature_test, col_names, feature_name)
```

&emsp;&emsp;定义函数格式:

```python
def fuction_name(params):
    #定义抽取特征的方式名
    feature_name = 'feature_name'
    
    #载入数据
    train_data ,test_data = before_extract_feature_load_data(
        train_file=project.preprocessed_data_dir + 'train_0.6_seg.csv',
        test_file=project.preprocessed_data_dir + 'test_0.4_seg.csv')
    
    #不同方式需要的数据 添加参数

    #用于保存特征的空数据集
    feature_train = np.zeros((train_data.shape[0], 1), dtype='float64')
    feature_test = np.zeros((test_data.shape[0], 1), dtype='float64')
    
    #不同方式定义的函数 添加函数
    
    #对两个数据集进行特征提取 
    for index,row in train_data.iterrows():
        s1 = row['s1'].strip().decode('utf-8')
        s2 = row['s2'].strip().decode('utf-8')
        #根据不同的方式提取特征
        feature_sim = feature_function()
        #保存每一行的提取特征
        feature_train[index] = round(feature_sim,5)

    for index, row in test_data.iterrows():
        s1 = row['s1'].strip().decode('utf-8')
        s2 = row['s2'].strip().decode('utf-8')
        feature_sim = feature_function(params)
        feature_test[index] = round(feature_sim,5)
    
    #保存提取特征
    col_names = [feature_name]
    after_extract_feature_save_data(feature_train,feature_test,col_names,feature_name)
    
```

- **长度差作为特征**

&emsp;&emsp;函数名extract_sentece_length_diff，方式名nlp_sentece_length_diff。定义函数get_length_diff计算两个句子的长度差特征，计算方法为1减去长度差的绝对值除以较长句长度。

```
#计算两个句子的长度差
def get_length_diff(s1, s2):
    return 1 - abs(len(s1) - len(s2)) / float(max(len(s1), len(s2)))
```

- **编辑距离作为特征**

  &emsp;&emsp;函数名extract_edit_distance，方式名nlp_edit_distance。定义函数get_edit_distance计算两个句子的编辑距离特征，计算方法与长度差特征类似为1减去编辑距离除以较长句长度。

  ```python
  #计算编辑距离 通过动态规划得到最少操作数
  def get_edit_distance(rawq1, rawq2):
      m, n = len(rawq1) + 1, len(rawq2) + 1
      matrix = [[0] * n for i in range(m)]
      matrix[0][0] = 0
      for i in range(1, m):
          matrix[i][0] = matrix[i - 1][0] + 1
      for j in range(1, n):
          matrix[0][j] = matrix[0][j - 1] + 1
      cost = 0
      for i in range(1, m):
          for j in range(1, n):
              if rawq1[i - 1] == rawq2[j - 1]:
                  cost = 0
              else:
                  cost = 1
              matrix[i][j] = min(matrix[i - 1][j] + 1, matrix[i][j - 1] + 1, matrix[i - 1][j - 1] + cost)
      return 1 - matrix[m - 1][n - 1] / float(max(len(rawq1), len(rawq2)))
  ```

- **ngram特征**

  &emsp;&emsp;函数名extract_ngram，方式名nlp_ngram。定义n_gram的方法的函数。

  ```python
  # 定义n_gram的方法 max_gram 设为3
  def get_ngram(rawq, ngram_value):
      result = []
      for i in range(len(rawq)):
          if i + ngram_value < len(rawq) + 1:
              result.append(rawq[i:i + ngram_value])
      return result
  
  def get_ngram_sim(q1_ngram, q2_ngram):
      q1_dict = {}
      q2_dict = {}
      for token in q1_ngram:
          if token not in q1_dict:
             q1_dict[token] = 1
          else:
              q1_dict[token] = q1_dict[token] + 1
      q1_count = np.sum([value for key, value in q1_dict.items()])
  
      for token in q2_ngram:
          if token not in q2_dict:
              q2_dict[token] = 1
          else:
              q2_dict[token] = q2_dict[token] + 1
      q2_count = np.sum([value for key, value in q2_dict.items()])
  
      # ngram1有但是ngram2没有
      q1_count_only = np.sum([value for key, value in q1_dict.items() if key not in q2_dict])
      # ngram2有但是ngram1没有
      q2_count_only = np.sum([value for key, value in q2_dict.items() if key not in q1_dict])
      # ngram1和ngram2都有的话，计算value的差值
      q1_q2_count = np.sum([abs(value - q2_dict[key]) for key, value in q1_dict.items() if key in q2_dict])
      # ngram1和ngram2的总值
      all_count = q1_count + q2_count
          
      return (1 - float(q1_count_only + q2_count_only + q1_q2_count) / (float(all_count) + 0.00000001))
  ```

- **两个句子的相同和不同的词的统计作为特征**

  &emsp;&emsp;函数名extract_sentence_diff_same，方式名nlp_sentece_diff_some，定义函数get_word_diff统计两个句子的相同和不同，返回结果包括相同占长句比例、占短句比例、占平均句长比例和不同分别占两个句子句长的比例，以及计算得到的jaccard相似度。

  ```python
  #统计两个句子的相同和不同
  def get_word_diff(q1, q2):
      set1 = set(q1.split(" "))
      set2 = set(q2.split(" "))
      same_word_len = len(set1 & set2)
      unique_word1_len = len(set1 - set2)
      unique_word2_len = len(set2 - set1)
      word1_len = len(set1)
      word2_len = len(set2)
      avg_len = (word1_len + word2_len) / 2.0
      max_len = max(word1_len, word2_len)
      min_len = min(word1_len, word2_len)
      jaccard_sim = same_word_len / float(len(set1 | set2))
  
      return same_word_len / float(max_len), same_word_len / float(min_len),\
             same_word_len / float(avg_len), unique_word1_len / float(word1_len),\
             unique_word2_len /float(word2_len), jaccard_sim
  ```

- **疑问词相同的比例作为特征**

  &emsp;&emsp;函数名extract_doubt_sim，方式名nlp_doubt_sim，载入数据除了train_data和test_data还有疑问词集doubt_words。定义函数get_doubt_sim用于获取疑问词相同的比例。

  ```python
  #获取疑问词集
  doubt_words = load_doubt_words(project.aux_dir + 'doubt_words.txt')
  
  #获取疑问词相同的比例
  def get_doubt_sim(q1, q2, doubt_words):
      q1_doubt_words = set(q1.split(" ")) & set(doubt_words)
      q2_doubt_words = set(q2.split(" ")) & set(doubt_words)
      return len(q1_doubt_words & q2_doubt_words) / float(len(q1_doubt_words | q2_doubt_words) + 1)
  ```

- **句子的词向量组合的相似度作为特征**

  &emsp;&emsp;函数名extract_word_embedding_sim，方式名nlp_word_embedding_sim，载入数据除了train_data和test_data还有词向量模型train_all_w2v_model，定义函数get_sen_vse来得到句子的词向量组合，定义函数get_sentece_embedding_sim，通过get_sen_vse得到词向量组合，然后计算余弦相似度来作为词向量组合的相似性。

  ```python
  train_all_w2v_model = KeyedVectors.load_word2vec_format(project.aux_dir + w2v_model_path, 
                                                          binary=False)
  #得到句子的词向量组合（tfidf）
  def get_sen_vec(q, train_all_w2v_model, tfidf_dict, tfidf_flag=True):
      sen_vec = 0
      for word in q.split(' '):
          if word in train_all_w2v_model.vocab:
              word_vec = train_all_w2v_model.word_vec(word)
              word_tfidf = tfidf_dict.get(word, None)
  
              if tfidf_flag == True:
                  sen_vec += word_vec * word_tfidf
              else:
                  sen_vec += word_vec
      sen_vec = sen_vec / np.sqrt(np.sum(np.power(sen_vec, 2)) + 0.000001)
      return sen_vec
      
  def get_sentece_embedding_sim(q1, q2, train_all_w2v_model, tfidf_dict, tfidf_flag=True):
      # 得到两个问句的词向量组合
      q1_sec = get_sen_vec(q1, train_all_w2v_model, tfidf_dict, tfidf_flag)
      q2_sec = get_sen_vec(q2, train_all_w2v_model, tfidf_dict, tfidf_flag)
  
      # 余弦相似度
      molecular = np.sum(np.multiply(q1_sec, q2_sec))
      denominator = np.sqrt(np.sum(np.power(q1_sec, 2))) * np.sqrt(np.sum(np.power(q2_sec, 2)))
      cos_sim = molecular / (denominator + 0.000001)
          
      return cos_sim
  ```

  

#### 4.3 模型设计

##### 4.3.1 **三个LSTM模型改进**

- **第一个LSTM模型**

  ```python
  def create_siamese_lstm_attention_model(embedding_matrix,model_param,embedding_size = 300,max_sentence_length = 20):
      
  ```

  第一步：定义孪生网络的公共层

  &emsp;&emsp;定义embedding_layer和lstm_layer这两个网络层，并为它们赋值，然后通过.add()方法一个个的将layer加入Sequential（快速开始序贯）模型中，我们就得到孪生网络的公共层share_model。

  ```python
  lstm_layer = LSTM(
      units=model_param['lstm_units']
      ,return_sequences=False
  )
  ```

   

  第二步：模型是多输入的结构，定义两个句子的输入

  &emsp;&emsp;因为我们训练集的输入格式是一行两个句子，左边那句为用户输入问句，右边那句为标准问题，所以我们定义了left_input和right_input通过Input (shape=(max_sentence_length,), dtype='int32')来存储。

   

  第三步：定义两个输入合并后的模型层

  &emsp;&emsp;left_input和right_input经过孪生网络的公共层share_model处理后，通过AttentionLayer1()合并，得到合并后的模型层matching_layer。再经过Dense全链接层的处理，最终得到merge_model模型。

   

  第四步：定义输出层

  &emsp;&emsp;定义输出层output_layer= Dense(1,activation='sigmoid')(merge_model)。

  &emsp;&emsp;定义mode1（模型1）输入为矩阵[left_input, right_input]，输出为矩阵[output_layer]。

  &emsp;&emsp;定义逻辑回归配置，优化器设置为adam，损失函数设置为binary_crossentropy，指标列表设置为metrics=['accuracy']，其中包含fbeta_score、precision、recall这三个指标。

   

  

  > *注：编译放在训练之前，我们通过compile来对学习过程进行配置。compile接收3个参数：*
  >
  > *&emsp;&emsp;l  优化器：Optimizer如：rmsprop,adagrad,*
  >
  > *&emsp;&emsp;l  损失函数：lossfunction*
  >
  > *&emsp;&emsp;l  指标列表：metrics=['accuracy']。一般是是性能评估*

   

  > &emsp;&emsp;*precision：精度指标。只计算按批处理的平均精度。计算精度，这是一个度量多标签分类的指标，用于确定有多少选择项是相关的。* 
  >
  > *&emsp;&emsp;recall：召回率。只计算批量平均召回率。计算召回量，这是一个用于多标签分类的指标，用于选择多少相关项。* 
  >
  > *&emsp;&emsp;fbeta_score：f值是精度和召回率的加权调和平均值。在这里，它只是按批处理的平均值计算，而不是全局平均值。这对于多标签分类非常有用，其中输入样本可以被分类为标签集。只有使用精确度(precision)，模型才能通过简单地为每个输入分配每个类来获得一个完美的分数。为了避免这种情况，度量还应该惩罚不正确的类分配(recall)。F-beta分数(范围从0.0到1.0)计算这个值，作为正确的班级分配比例与错误班级分配比例的加权平均值。*
  >
  > *&emsp;&emsp;当beta= 1时，它等于F-measure；在beta < 1中，分配正确的类变得更加重要，而在beta > 1中，度量的权重是惩罚不正确的类分配。*

- **第二个LSTM模型**

  ```python
  def create_siamese_lstm_ManDistance_model(embedding_matrix,model_param,embedding_size = 300,max_sentence_length = 20):
      
  ```

  &emsp;&emsp;与第一个LSTM模型的步骤相似。

  &emsp;&emsp;lstm_layer不同，多了dropout和recurrent_dropout参数的传入，如下图：

  ```python
  lstm_layer = LSTM(
      units=model_param['lstm_units'],
      dropout=model_param['lstm_dropout_rate'],
      recurrent_dropout=model_param['lstm_re_dropout_rate'],
  
      return_sequences=False
  )
  ```

  &emsp;&emsp;output_layer也不同，output_layer=Dense(1,activation='softmax')( ManDist()([s1_net,s2_net]))。

  &emsp;&emsp;逻辑回归配置的损失函数设置也改变了，变为categorical_crossentropy。

  

- **第三个LSTM模型**

  ```python
  def create_siamese_lstm_dssm_mdoel(embedding_matrix,embedding_word_matrix,model_param,embedding_size = 300,max_sentence_length = 20,max_word_length=25):
      
  ```

  &emsp;&emsp;在前两个模型的基础上改进。

  &emsp;&emsp;第一部分，该模型是基于论文《A Decomposable Attention Model for Natural Language Inference》中的Attention机制，在语句中的词级别上添加了注意力机制，让经过LSTM编码后的语义向量在语句中的词上更有了重心，主要体现在语句中各个词的词向量经过attention机制后的权重分配不一样了。此外，还借助了该论文中的Compare部分，将attention机制表示的语句词向量与双向LSTM语义编码的向量进行Concatenate连接。

  &emsp;&emsp;第二部分，模型三除了以两个语句的词组级别的向量作为输入外，还增加了两个语句的字级别的向量作为输入。增加字符级的输入，主要是为了解决out-of-vocabulary词组级别的问题。第三部分，在语句的词向量的语义向量上添加了基于CNN的交互式处理思想，这种方式考虑了句子之间的所有交互属性。

##### 4.3.2 **Stacking模型的融合（决策树）**

> &emsp;&emsp;*Stacking分类模型的建立工作:*
>
> *&emsp;&emsp;通过上述的特征提取方法将会提取出19个特征，通过对提取出的特征使用机器学习建立分类模型。一开始选择使用了基本的sklearn中的LogisticRegression分类方法。后来提出使用集成学习中的Stacking模式将Sklearn中的多个分类学习方法进行融合，使 F1结果得到提升。*

- **引入模块**

  &emsp;&emsp;从sklearn.naive_bayes引入模块GaussianNB

  &emsp;&emsp;从sklearn.tree引入模块DecisionTreeClassifier

  &emsp;&emsp;从sklearn.ensemble引入模块RandomForestClassifier

  &emsp;&emsp;从sklearn.linear_model引入模块LogisticRegression

  &emsp;&emsp;引入模块lightgbm 

  

  > *Lightgbm 是一个梯度 boosting 框架, 使用基于学习算法的决策树. 它是分布式的, 高效性：*
  >
  > *&emsp;&emsp;l  更快的培训速度和更高的效率。*
  >
  > *&emsp;&emsp;l  降低内存使用率。*
  >
  > *&emsp;&emsp;l  更准确。*
  >
  > *&emsp;&emsp;l  支持并行和GPU学习。*
  >
  > *&emsp;&emsp;l  能够处理大规模数据。*

  

- **定义StackingBaseClassifier类**

  &emsp;&emsp;定义Stacking基础类StackingBaseClassifier，此类里定义了三个函数，分别为：train(self, x_train, y_train, x_val=None, y_val=None)，主要用于Stacking的基础模型的训练，return:model。

  

  &emsp;&emsp;predict(self, model, x_test)

  &emsp;&emsp;主要用于Stacking的基础模型的预测。

  

  &emsp;&emsp;get_model_out(self, x_train, y_train, x_test, n_fold=5)

  &emsp;&emsp;交叉验证预测出基础模型的输出，返回train_oofp（存储训练集中每个fold的预测结果），test_oofp_mean（存储对测试集预测结果的平均值）。

  

- **定义GussianNBClassifier类**

  &emsp;&emsp;定义GussianNBClassifier类继承了础类StackingBaseClassifier。

  &emsp;&emsp;重定义了train(self, x_train, y_train, x_val, y_val)，其中调用了：

  &emsp;&emsp;gnb = GaussianNB()

  &emsp;&emsp;gnb.fit(x_train, y_train)

  &emsp;&emsp;最后返回gnb这个用x_train、y_train训练好的模型。

   

  &emsp;&emsp;重定义了predict(self, model, x_test)，返回对应GussianNB训练的模型对于测试集x_test的预测结果。

  

- **定义LGBClassifier类**

  &emsp;&emsp;定义LGBClassifier类继承了础类StackingBaseClassifier。

  &emsp;&emsp;定义了__init__(self)函数，初始化如下：

  ```python
  def __init__(self):
      self.lgb_param = {
          'objective': 'binary',
          'metric': {'auc', 'binary_logloss'},
          'boosting': 'gbdt',
          'device': 'cpu',
          'feature_fraction': 0.8,  # 抽取所有特征的0.75个进行训练
          'num_leaves': 16,
          'learning_rate': 0.01,
          'verbose': 1,
          'bagging_seed': 456,
          'feature_fraction_seed': 456
      }
  ```

  &emsp;&emsp;重定义了train(self, x_train, y_train, x_val, y_val)，其中训练模型调用了Lightgbm.train()函数，其中传入的参数训练集和测试集都需要验证。

  &emsp;&emsp;最后返回Lightgbm训练好的模型，训练如下：

  ```python
  def train(self, x_train, y_train, x_val, y_val):
      print ('use LGB train model...')
  
      lgb_data_train = lgb.Dataset(x_train, y_train)
      lgb_data_val = lgb.Dataset(x_val, y_val)
      evals_res = {}
  
      model = lgb.train(
          params=self.lgb_param,
          train_set=lgb_data_train,
          valid_sets=[lgb_data_train, lgb_data_val],  # 训练集和测试集都需要验证
          valid_names=['train', 'val'],
          evals_result=evals_res,
          num_boost_round=2500,
          early_stopping_rounds=10,
          verbose_eval=False
      )
  
      return model
  ```

  &emsp;&emsp;重定义了predict(self, model, x_test)类似GussianNBClassifier类的predict函数。

  

- **定义RFClassifer类**

  &emsp;&emsp;定义RFClassifer类继承了础类StackingBaseClassifier。

  &emsp;&emsp;重定义了train(self, x_train, y_train, x_val, y_val)，其中使用了RandomForestClassifier类，

  &emsp;&emsp;最后返回Lightgbm训练好的模型，训练如下：

  ```python
  def train(self, x_train, y_train, x_val, y_val):
      print ('use RandomForest train model...')
  
      clf = RandomForestClassifier(n_estimators=25,
                                   max_depth=4,
                                   class_weight={
                                       0: 1,
                                       1: 4
                                   }
                                   )
                                   
      clf.fit(x_train, y_train)
      return clf
  ```

  

  > *n_estimators: 也就是弱学习器的最大迭代次数，或者说最大的弱学习器的个数。一般来说n_estimators太小，容易欠拟合，n_estimators太大，计算量会太大，并且n_estimators到一定的数量后，再增大n_estimators获得的模型提升会很小，所以一般选择一个适中的数值。默认是100。*
  >
  > 
  >
  > *max_depth: 决策树最大深度，默认可以不输入，如果不输入的话，决策树在建立子树的时候不会限制子树的深度。一般来说，数据少或者特征少的时候可以不管这个值。如果模型样本量多，特征也多的情况下，推荐限制这个最大深度，具体的取值取决于数据的分布。常用的可以取值10-100之间。*
  >
  > 
  >
  > *class_weight=None：各个label的权重。*

  

  &emsp;&emsp;可以看出，我们train的弱学习最大迭代次数是25；因为文本相似的数据和特征都不少，所以决策树最大深度max_depth不能默认，设为4；0标签，也就是不相似的权重为1，1标签，也就是相似的权重为4。

  &emsp;&emsp;重定义了predict(self, model, x_test)类似GussianNBClassifier类的predict函数。

  

- **定义LogisicClassifier类**

  &emsp;&emsp;定义LogisicClassifier类继承了础类StackingBaseClassifier。

  &emsp;&emsp;重定义了train(self, x_train, y_train, x_val, y_val)，其中使用了LogisticRegression类，

  &emsp;&emsp;最后返回LogisticRegression训练好的模型，训练如下：

  ```python
  def train(self, x_train, y_train, x_val=None, y_val=None):
      print ('use LogisticRegression train model...')
      lr = LogisticRegression(class_weight={0: 1, 1: 4})
      lr.fit(x_train, y_train)
      return lr
  ```

  &emsp;&emsp;可以看出，我们train的各标签权重：0标签，也就是不相似的权重为1；1标签，也就是相似的权重为4。

  &emsp;&emsp;重定义了predict(self, model, x_test)类似GussianNBClassifier类的predict函数。

  

- **定义DecisionClassifier类**

  &emsp;&emsp;定义DecisionClassifier类继承了础类StackingBaseClassifier。

  &emsp;&emsp;重定义了train(self, x_train, y_train, x_val, y_val)，其中使用了DecisionTreeClassifier类，

  &emsp;&emsp;最后返回DecisionTreeClassifier训练好的模型，训练如下：

  ```python
  def train(self, x_train, y_train, x_val=None, y_val=None):
      print ('use DecisionClassifier train model...')
  
      dt = DecisionTreeClassifier(class_weight={0: 1, 1: 4},max_depth=5)
      dt.fit(x_train, y_train)
  
      return dt
  ```

  &emsp;&emsp;可以看出，我们train的各标签权重：0标签，也就是不相似的权重为1；1标签，也就是相似的权重为4。策树最大深度max_depth为4。

  &emsp;&emsp;重定义了predict(self, model, x_test)类似GussianNBClassifier类的predict函数。

  

- **Stacking模型的融合**

  &emsp;&emsp;最后使用了两层Stacking方式，选用了GussianNBClassifier、RandomForestClassifier、LogisticRegression、DecisionTreeClassifier四个基分类器作为第一层Stacking基模型。第二层Stacking选用的是RandomForestClassifier分类器进行训练的。具体实现的方式为：

  ```python
  # stacking 第一层模型训练,分别使用基分类器对训练集X_train进行5折交叉验证，在使用训练的模型预测X_test取均值。作为第二层Stacking模型的输入。
  gnb_cls = GussianNBClassifier()
  gnb_oop_train, gnb_oofp_val = gnb_cls.get_model_out(, y_train, X_test)
  
  
  rf_cls = RFClassifer()
  rf_oop_train, rf_oofp_val = rf_cls.get_model_out(X_train, y_train, X_test)
  
  
  lg_cls = LogisicClassifier()
  lg_oop_train, lg_oofp_val = lg_cls.get_model_out(X_train, y_train, X_test)
  
  
  dt_cls = DecisionClassifier()
  dt_oop_train, dt_oofp_val = dt_cls.get_model_out(X_train, y_train, X_test)
  
  # 构造第二层Stacking模型的输入
  input_train = [gnb_oop_train, rf_oop_train, lg_oop_train, dt_oop_train]
  input_test = [gnb_oofp_val, rf_oofp_val, lg_oofp_val, dt_oofp_val]
  
  
  stacked_train = np.concatenate([data.reshape(-1, 1) for data in input_train], axis=1)
  stacked_test = np.concatenate([data.reshape(-1, 1) for data in input_test], axis=1)
  
  
  # stacking 第二层模型训练
  second_model = DecisionTreeClassifier(max_depth=3, class_weight={0: 1, 1: 4})
  second_model.fit(stacked_train, y_train)
  ```

  

## 第五章 模型效果

### 5.1 模型结果

nepoch  1  url 5000 final 15000

| model | F1                 | recall_score       | accuracy_score |
| ----- | ------------------ | ------------------ | -------------- |
| NaN   | 0.7738095238095237 | 0.9348978046934141 | 0.7112         |
| 1     | 0.7721995607154063 | 0.9314912944738835 | 0.7096         |
| 2     | 0.7286949361877315 | 0.6699470098410295 | 0.7364         |
| 3     | 0.7841363715428771 | 0.8531415594246783 | 0.7518         |
| all   | 0.7536174430128841 | 0.7195306585919757 | 0.7514         |

测试集 s2 = std

| model | F1                 | recall_score       | accuracy_score |
| ----- | ------------------ | ------------------ | -------------- |
| NaN   | 0.548351034097261  | 0.9684106614017769 | 0.6768         |
| 1     | 0.537703170796696  | 0.9960513326752222 | 0.653          |
| 2     | 0.6898263027295285 | 0.9605133267522211 | 0.825          |
| 3     | 0.5646992054483542 | 0.9822309970384995 | 0.6932         |
| all   | 0.6648757555406314 | 0.9772951628825272 | 0.8004         |

### 5.2 模型分析

- **LSTM-ManDistance**

  &emsp;&emsp;基于LSTM进行语义编码的曼哈顿距离相似度和余弦相似度的模型，该模型主要是简单对输入的语句序列进行LSTM的编码获取得到句子的语义表示向量，再经过语义向量的曼哈顿计算和余弦距离计算，最后依据这两项训练出模型参数。

- **LSTM-Attention**

  &emsp;&emsp;Attention机制的基本思想是，打破了传统编码器-解码器结构在编解码时都依赖于内部一个固定长度向量的限制。

  &emsp;&emsp;Attention机制的实现是通过保留LSTM编码器对输入序列的中间输出结果，然后训练一个模型来对这些输入进行选择性的学习并且在模型输出时将输出序列与之进行关联。

  虽然模型使用attention机制之后会增加计算量，但是性能水平能够得到提升。

- **LSTM-DSSM**

  &emsp;&emsp;在语句的词向量的语义向量上添加了基于CNN的交互式处理思想，这种方式考虑了句子之间的所有交互属性。

  
